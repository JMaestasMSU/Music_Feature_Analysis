{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1500680c",
   "metadata": {},
   "source": [
    "# CNN Development: End-to-End Spectrogram Classification\n",
    "\n",
    "This notebook implements a Convolutional Neural Network (CNN) that processes raw spectrograms for music genre classification, demonstrating end-to-end learning from time-frequency representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e9bb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import librosa\n",
    "import librosa.display\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from models.cnn_model import AudioCNN, CNNTrainer, create_spectrogram_dataset\n",
    "\n",
    "# Check GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3bbd4a",
   "metadata": {},
   "source": [
    "## 1. Generate Sample Spectrogram Data\n",
    "\n",
    "Create demonstration spectrograms for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fbe2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic spectrogram dataset for demonstration\n",
    "n_samples = 2000\n",
    "n_genres = 8\n",
    "genres = ['rock', 'electronic', 'hip-hop', 'classical', 'jazz', 'folk', 'pop', 'experimental']\n",
    "\n",
    "# Spectrogram shape: (frequency bins, time frames)\n",
    "spec_height = 128  # Frequency bins\n",
    "spec_width = 128   # Time frames\n",
    "\n",
    "print(f\"Generating {n_samples} synthetic spectrograms...\")\n",
    "print(f\"Spectrogram shape: ({spec_height}, {spec_width})\")\n",
    "\n",
    "# Generate spectrograms with genre-specific characteristics\n",
    "spectrograms = np.zeros((n_samples, spec_height, spec_width))\n",
    "labels = np.zeros(n_samples, dtype=int)\n",
    "\n",
    "for i in range(n_samples):\n",
    "    genre_idx = i % n_genres\n",
    "    labels[i] = genre_idx\n",
    "    \n",
    "    # Create genre-specific spectrogram patterns\n",
    "    spec = np.random.randn(spec_height, spec_width) * 0.1\n",
    "    \n",
    "    if genre_idx == 0:  # rock\n",
    "        spec[40:80, :] += np.random.uniform(0.5, 1.5, (40, spec_width))\n",
    "    elif genre_idx == 1:  # electronic\n",
    "        spec[60:100, :] += np.random.uniform(0.8, 1.5, (40, spec_width))\n",
    "    elif genre_idx == 2:  # hip-hop\n",
    "        spec[20:60, :] += np.random.uniform(0.6, 1.2, (40, spec_width))\n",
    "    elif genre_idx == 3:  # classical\n",
    "        spec[:, :] += np.linspace(0.1, 1.0, spec_width) * 0.5\n",
    "    elif genre_idx == 4:  # jazz\n",
    "        spec[30:100, :] += np.random.uniform(0.3, 1.2, (70, spec_width))\n",
    "    elif genre_idx == 5:  # folk\n",
    "        spec[50:110, :] += np.random.uniform(0.4, 1.0, (60, spec_width))\n",
    "    elif genre_idx == 6:  # pop\n",
    "        spec[50:90, :] += np.random.uniform(0.7, 1.3, (40, spec_width))\n",
    "    elif genre_idx == 7:  # experimental\n",
    "        spec[:, :] += np.abs(np.random.randn(spec_height, spec_width)) * 0.3\n",
    "    \n",
    "    spectrograms[i] = np.abs(spec)\n",
    "\n",
    "print(f\"Generated spectrograms shape: {spectrograms.shape}\")\n",
    "print(f\"Labels distribution:\\n{pd.Series(labels).value_counts().sort_index()}\")\n",
    "\n",
    "# Normalize spectrograms\n",
    "spectrograms = (spectrograms - spectrograms.mean()) / (spectrograms.std() + 1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d81c0e",
   "metadata": {},
   "source": [
    "## 2. Visualize Sample Spectrograms\n",
    "\n",
    "Examine spectrograms for different genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b198ec7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample spectrograms\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "fig.suptitle('Sample Spectrograms by Genre', fontsize=16, fontweight='bold')\n",
    "\n",
    "for genre_idx in range(n_genres):\n",
    "    ax = axes[genre_idx // 4, genre_idx % 4]\n",
    "    sample_idx = np.where(labels == genre_idx)[0][0]\n",
    "    \n",
    "    im = ax.imshow(spectrograms[sample_idx], aspect='auto', origin='lower', cmap='viridis')\n",
    "    ax.set_title(genres[genre_idx], fontweight='bold')\n",
    "    ax.set_xlabel('Time Frames')\n",
    "    ax.set_ylabel('Frequency Bins')\n",
    "    plt.colorbar(im, ax=ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/cnn_sample_spectrograms.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b1c722",
   "metadata": {},
   "source": [
    "## 3. Create Data Loaders\n",
    "\n",
    "Prepare training, validation, and test sets with stratification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dad9465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified split: 60% train, 20% val, 20% test\n",
    "train_idx, temp_idx = train_test_split(\n",
    "    np.arange(n_samples), test_size=0.4, stratify=labels, random_state=42\n",
    ")\n",
    "val_idx, test_idx = train_test_split(\n",
    "    temp_idx, test_size=0.5, stratify=labels[temp_idx], random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train samples: {len(train_idx)}\")\n",
    "print(f\"Val samples: {len(val_idx)}\")\n",
    "print(f\"Test samples: {len(test_idx)}\")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader, val_loader, test_loader = create_spectrogram_dataset(\n",
    "    spectrograms, labels, train_idx, val_idx, test_idx\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain loader batches: {len(train_loader)}\")\n",
    "print(f\"Val loader batches: {len(val_loader)}\")\n",
    "print(f\"Test loader batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44d7980",
   "metadata": {},
   "source": [
    "## 4. Initialize and Train CNN Model\n",
    "\n",
    "Build and train the CNN architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02464b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = AudioCNN(num_genres=n_genres, input_channels=1)\n",
    "print(\"Model architecture:\")\n",
    "print(model)\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = CNNTrainer(model, device=device, learning_rate=0.001, weight_decay=1e-5)\n",
    "\n",
    "# Train model\n",
    "history = trainer.train(\n",
    "    train_loader, val_loader, epochs=50, patience=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d10cfb",
   "metadata": {},
   "source": [
    "## 5. Visualize Training History\n",
    "\n",
    "Plot training and validation curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2b4020",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.plot_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bd0a8d",
   "metadata": {},
   "source": [
    "## 6. Evaluate on Test Set\n",
    "\n",
    "Comprehensive evaluation with confusion matrix and metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6e7f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "predictions, true_labels = trainer.evaluate(test_loader, genres)\n",
    "\n",
    "# Calculate metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "f1_weighted = f1_score(true_labels, predictions, average='weighted')\n",
    "precision = precision_score(true_labels, predictions, average='weighted')\n",
    "recall = recall_score(true_labels, predictions, average='weighted')\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"CNN TEST SET PERFORMANCE\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"F1-Score:  {f1_weighted:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e357b30",
   "metadata": {},
   "source": [
    "## 7. Comparative Analysis\n",
    "\n",
    "Compare CNN with baseline models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279c7e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten spectrograms for traditional ML models\n",
    "specs_flat = spectrograms.reshape(n_samples, -1)\n",
    "\n",
    "X_train_flat = specs_flat[train_idx]\n",
    "X_val_flat = specs_flat[val_idx]\n",
    "X_test_flat = specs_flat[test_idx]\n",
    "\n",
    "y_train = labels[train_idx]\n",
    "y_val = labels[val_idx]\n",
    "y_test = labels[test_idx]\n",
    "\n",
    "# Train Random Forest for comparison\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "print(\"Training Random Forest for comparison...\")\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=15, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train_flat, y_train)\n",
    "\n",
    "rf_pred = rf_model.predict(X_test_flat)\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "rf_f1 = f1_score(y_test, rf_pred, average='weighted')\n",
    "\n",
    "print(f\"\\nRandom Forest Accuracy:  {rf_accuracy:.4f}\")\n",
    "print(f\"Random Forest F1-Score:  {rf_f1:.4f}\")\n",
    "\n",
    "# Comparison table\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['CNN', 'Random Forest'],\n",
    "    'Accuracy': [accuracy, rf_accuracy],\n",
    "    'F1-Score': [f1_weighted, rf_f1],\n",
    "    'Precision': [precision, precision_score(y_test, rf_pred, average='weighted')],\n",
    "    'Recall': [recall, recall_score(y_test, rf_pred, average='weighted')]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Visualization\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "x = np.arange(len(comparison_df))\n",
    "width = 0.2\n",
    "metrics = ['Accuracy', 'F1-Score', 'Precision', 'Recall']\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax.bar(x + i*width, comparison_df[metric], width, label=metric, alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Model')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('CNN vs Random Forest: Performance Comparison')\n",
    "ax.set_xticks(x + width * 1.5)\n",
    "ax.set_xticklabels(comparison_df['Model'])\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "ax.set_ylim([0, 1.0])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/cnn_vs_rf_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

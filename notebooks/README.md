# Notebooks Directory

This directory contains Jupyter notebooks for the Music Feature Analysis project.

## Grading Deliverables (Baseline - 8 Genres)

### Original Notebooks (Backed Up)
- **`01_EDA_baseline.ipynb`** - Original baseline EDA (8 genres, single-label)
- **`02_Modeling_baseline.ipynb`** - Original baseline modeling (8 genres, single-label)

These notebooks represent the original course deliverables and are preserved for grading purposes.

### Updated Advanced Notebooks (22 Genres, Multi-Label)
- **`01_EDA.ipynb`** - Advanced EDA with 22 subgenres and multi-label support
- **`02_Modeling.ipynb`** - Advanced multi-label CNN modeling with 22 genres

## Additional Research Notebooks

### Advanced CNN Development
- **`multilabel_cnn_demo.ipynb`** - Interactive demo of multi-label CNN (50-70 genres)
  - Architecture comparison (baseline vs advanced)
  - Data augmentation examples (SpecAugment, Mixup)
  - Multi-label training visualization
  - Embedding visualization with UMAP

- **`cnn_development.ipynb`** - Original CNN development (8 genres)
  - Initial architecture experiments
  - Feature extraction pipeline
  - Single-label classification

### Hyperparameter Optimization
- **`bayesian_optimization.ipynb`** - Automated hyperparameter tuning
  - Bayesian optimization implementation
  - Grid search comparison
  - Learning rate, batch size, architecture tuning
  - 10x faster than grid search

## Key Differences: Baseline vs Advanced

| Aspect | Baseline (01_EDA_baseline) | Advanced (01_EDA) |
|--------|---------------------------|-------------------|
| **Genres** | 8 top-level genres | 22 target subgenres |
| **Classification** | Single-label | Multi-label |
| **Features** | 58 hand-crafted features | Spectrograms + features |
| **Model** | Random Forest baseline | Multi-label CNN |
| **Dataset** | GTZAN-like (1K tracks) | FMA subset (~16.5K tracks) |
| **Architecture** | Traditional ML | ResNet-style CNN |
| **Spectrograms** | N/A | 2 per genre (44 total) |

## Running the Notebooks

### Prerequisites
```bash
# Activate environment
conda activate mfa-cpu  # or mfa-gpu-cuda11-8 for training

# Ensure Jupyter is installed
conda install jupyter

# Navigate to notebooks directory
cd notebooks/
```

### Execution Order

#### For Baseline (Grading)
```bash
# 1. Run baseline EDA
jupyter notebook 01_EDA_baseline.ipynb

# 2. Run baseline modeling
jupyter notebook 02_Modeling_baseline.ipynb
```

#### For Advanced System
```bash
# 1. Extract features first (required)
cd ..
python scripts/extract_audio_features.py --use-subgenres --spectrograms-per-genre 2 --samples-per-genre 1000 --num-workers 8

# 2. Run advanced EDA
jupyter notebook notebooks/01_EDA.ipynb

# 3. Prepare spectrograms for CNN
python scripts/prepare_cnn_spectrograms.py --use-subgenres --multi-label

# 4. Run advanced modeling
jupyter notebook notebooks/02_Modeling.ipynb

# 5. (Optional) Explore CNN demo
jupyter notebook notebooks/multilabel_cnn_demo.ipynb
```

## Data Requirements

### For Baseline Notebooks
- **Extracted features**: `data/processed/extracted_features.pkl`
  - Generated by: `python scripts/extract_audio_features.py`
- **Spectrogram examples**: `data/processed/spectrograms/*.png`
  - Generated automatically during feature extraction

### For Advanced Notebooks
- **Extracted features with subgenres**: `data/processed/extracted_features.pkl`
  - Generated by: `python scripts/extract_audio_features.py --use-subgenres --samples-per-genre 1000 --num-workers 8`
  - Creates 22 target subgenres with up to 1000 samples each (~16.5K total)
- **Spectrogram examples**: `data/processed/spectrograms/*.png`
  - Generated automatically (2 examples per genre)
  - Used for CNN training in modeling notebook
- **Multi-label labels**: `data/processed/labels_multilabel.npy`
  - Generated by: `python scripts/prepare_cnn_spectrograms.py --multi-label`
- **Genre names**: `data/processed/genre_names_22.json`
  - Generated automatically with spectrograms

## What Each Notebook Contains

### 01_EDA.ipynb (Advanced)
1. Dataset overview with 22 target subgenres
2. Data quality assessment with imbalance analysis
3. Feature exploration (spectrograms + audio features)
4. Correlation analysis for multi-label features
5. Genre-specific characteristics across subgenres
6. Data preprocessing for multi-label CNN
7. Key insights for multi-genre classification
8. Multi-label strategy justification
9. Export preprocessed data (~750 samples per genre, ~16.5K total)

### 02_Modeling.ipynb (Advanced)
1. Load spectrogram images from EDA dataset (44 spectrograms, 2 per genre)
2. Multi-label CNN architecture (ResNet-style)
3. Training with multi-label loss (BCEWithLogitsLoss)
4. Evaluation metrics (F1, precision, recall per genre)
5. Confusion matrix for ~22 genres
6. Per-genre performance analysis
7. Training dynamics visualization
8. Error analysis and insights
9. Educational explanations of CNN concepts

### multilabel_cnn_demo.ipynb (Demo)
- Interactive walkthrough of the advanced CNN
- Visualizations of architecture and training
- Live prediction examples
- Comparison with baseline
- Best for presentations and understanding the system

## Expected Outputs

### Baseline Notebooks
- **Accuracy**: ~45-55% (8-class, random=12.5%)
- **Best genres**: Electronic, Classical (distinct)
- **Challenging**: Rock, Pop (overlap)

### Advanced Notebooks
- **F1 Score**: ~0.50-0.65 (multi-label, 22 genres)
- **Dataset**: ~16.5K samples (~750 per genre), 44 spectrogram images (2 per genre)
- **Best genres**: Electronic subgenres, Experimental (distinct patterns)
- **Challenging**: Similar subgenres within same parent
- **Multi-label performance**: Hamming loss < 0.20

## Troubleshooting

### "No features found"
```bash
# Run feature extraction (creates features + spectrograms)
python scripts/extract_audio_features.py --use-subgenres --num-spectrogram-examples 2 --samples-per-genre 100
```

### "Spectrograms not found"
```bash
# Spectrograms are generated automatically during feature extraction
# Check: data/processed/spectrograms/*.png (should have ~44 files, 2 per genre)
```

### "Kernel crashes" or "Out of memory"
- Use smaller batch sizes in training cells
- Reduce `samples_per_genre` in extraction
- Close other applications
- Use CPU environment for inference

### "Computer freezes during feature extraction"
```bash
# Limit parallel workers to prevent system crash (default uses ALL CPU cores)
python scripts/extract_audio_features.py --use-subgenres --num-workers 4 --samples-per-genre 100

# Recommended: Use 50-75% of your CPU cores
# 4-core CPU: --num-workers 2-3
# 8-core CPU: --num-workers 4-6
# 12-core CPU: --num-workers 6-9
```

### "ModuleNotFoundError"
```bash
# Ensure environment is activated
conda activate mfa-cpu

# Reinstall dependencies
pip install -r requirements.txt
```

## Outputs Generated

Notebooks automatically save visualizations to:
```
presentation/figures/
├── 00_spectrograms_examples.png    (Spectrogram visualizations)
├── 01_genre_distribution.png       (Genre counts)
├── 02_feature_distributions.png    (Box plots)
├── 03_correlation_matrix.png       (Feature correlations)
├── 04_genre_profiles.png           (Heatmap of genre characteristics)
├── 05_feature_importance.png       (F-statistics)
├── 06_normalization_comparison.png (Scaler comparison)
└── ... (additional modeling plots)
```

## Next Steps After Running Notebooks

1. **Review Results**: Check `presentation/figures/` for all visualizations
2. **Train Full Model**: `python scripts/train_multilabel_cnn.py --num-genres 22 ...`
3. **Deploy API**: `cd backend && python app.py`
4. **Test Predictions**: Upload songs to API at `http://localhost:8000/docs`

## Contributing

When adding new notebooks:
1. Follow naming convention: `##_Description.ipynb`
2. Include markdown cells explaining each section
3. Save outputs for reproducibility
4. Document data dependencies at top
5. Update this README with new notebook description

## See Also

- [README.md](../README.md) - Project overview
- [scripts/README.md](../scripts/README.md) - Script documentation
- [ADVANCED_CNN_GUIDE.md](../ADVANCED_CNN_GUIDE.md) - Technical CNN details

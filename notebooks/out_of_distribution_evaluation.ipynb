{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02337ced",
   "metadata": {},
   "source": [
    "# Out-of-Distribution (OOD) Evaluation\n",
    "\n",
    "This notebook evaluates model robustness on out-of-distribution music samples—tracks that differ systematically from the training distribution. This is critical for understanding real-world deployment performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7097fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "\n",
    "print(\"Out-of-Distribution Robustness Evaluation\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9139c14",
   "metadata": {},
   "source": [
    "## 1. Create OOD Datasets\n",
    "\n",
    "Generate systematically different distributions to simulate real-world scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0cf8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# In-distribution training data\n",
    "n_train = 2000\n",
    "n_genres = 8\n",
    "genres = ['rock', 'electronic', 'hip-hop', 'classical', 'jazz', 'folk', 'pop', 'experimental']\n",
    "\n",
    "X_in_dist = np.random.normal(0, 1, (n_train, 20))\n",
    "y_train = np.random.randint(0, n_genres, n_train)\n",
    "\n",
    "# In-distribution test data\n",
    "n_test = 500\n",
    "X_in_dist_test = np.random.normal(0, 1, (n_test, 20))\n",
    "y_in_dist_test = np.random.randint(0, n_genres, n_test)\n",
    "\n",
    "print(f\"In-distribution training: {X_in_dist.shape}\")\n",
    "print(f\"In-distribution test: {X_in_dist_test.shape}\")\n",
    "\n",
    "# Create OOD datasets with different characteristics\n",
    "print(\"\\nGenerating OOD datasets...\")\n",
    "\n",
    "# OOD 1: Shifted mean (music with different loudness/energy)\n",
    "X_ood_shifted = np.random.normal(2.0, 1, (n_test, 20))\n",
    "y_ood_shifted = np.random.randint(0, n_genres, n_test)\n",
    "print(\"  ✓ OOD Shifted: Mean shift of 2.0 (different audio energy)\")\n",
    "\n",
    "# OOD 2: Increased variance (extreme dynamics)\n",
    "X_ood_high_var = np.random.normal(0, 3, (n_test, 20))\n",
    "y_ood_high_var = np.random.randint(0, n_genres, n_test)\n",
    "print(\"  ✓ OOD High Variance: 3x increased std dev (extreme dynamics)\")\n",
    "\n",
    "# OOD 3: Sparse features (missing information / lossy compression)\n",
    "X_ood_sparse = np.random.choice([0, np.nan], (n_test, 20), p=[0.3, 0.7])\n",
    "X_ood_sparse = np.nan_to_num(X_ood_sparse)  # Replace NaN with 0\n",
    "y_ood_sparse = np.random.randint(0, n_genres, n_test)\n",
    "print(\"  ✓ OOD Sparse: 70% missing features (compressed audio)\")\n",
    "\n",
    "# OOD 4: Corrupted features (noise / degraded audio)\n",
    "X_ood_noisy = np.random.normal(0, 1, (n_test, 20)) + np.random.normal(0, 2, (n_test, 20))\n",
    "y_ood_noisy = np.random.randint(0, n_genres, n_test)\n",
    "print(\"  ✓ OOD Noisy: Added Gaussian noise (degraded quality)\")\n",
    "\n",
    "# OOD 5: Bimodal distribution (mixture of genres / covers)\n",
    "X_ood_bimodal_1 = np.random.normal(-1.5, 0.8, (n_test//2, 20))\n",
    "X_ood_bimodal_2 = np.random.normal(1.5, 0.8, (n_test//2, 20))\n",
    "X_ood_bimodal = np.vstack([X_ood_bimodal_1, X_ood_bimodal_2])\n",
    "y_ood_bimodal = np.random.randint(0, n_genres, n_test)\n",
    "print(\"  ✓ OOD Bimodal: Mixture of two distributions (cover songs)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992d3cdc",
   "metadata": {},
   "source": [
    "## 2. Train Model on In-Distribution Data\n",
    "\n",
    "Train model on standard training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f700ec7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize in-distribution data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_in_dist)\n",
    "X_test_scaled = scaler.transform(X_in_dist_test)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=15, random_state=42, n_jobs=-1)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate on in-distribution test set\n",
    "y_pred_in = model.predict(X_test_scaled)\n",
    "y_pred_proba_in = model.predict_proba(X_test_scaled)\n",
    "\n",
    "in_dist_accuracy = accuracy_score(y_in_dist_test, y_pred_in)\n",
    "in_dist_f1 = f1_score(y_in_dist_test, y_pred_in, average='weighted')\n",
    "\n",
    "print(f\"In-Distribution Performance:\")\n",
    "print(f\"  Accuracy:  {in_dist_accuracy:.4f}\")\n",
    "print(f\"  F1-Score:  {in_dist_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a894d9",
   "metadata": {},
   "source": [
    "## 3. Evaluate on OOD Datasets\n",
    "\n",
    "Test model robustness across different OOD scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82424d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate on OOD data\n",
    "def evaluate_ood(X_ood, y_ood, scaler, model, ood_name):\n",
    "    \"\"\"Evaluate model on OOD data.\"\"\"\n",
    "    try:\n",
    "        X_ood_scaled = scaler.transform(X_ood)\n",
    "    except:\n",
    "        # Handle NaN or inf values\n",
    "        X_ood_scaled = np.nan_to_num(scaler.transform(X_ood), nan=0.0, posinf=1.0, neginf=-1.0)\n",
    "    \n",
    "    y_pred_ood = model.predict(X_ood_scaled)\n",
    "    y_pred_proba_ood = model.predict_proba(X_ood_scaled)\n",
    "    \n",
    "    accuracy = accuracy_score(y_ood, y_pred_ood)\n",
    "    f1 = f1_score(y_ood, y_pred_ood, average='weighted')\n",
    "    \n",
    "    # Compute confidence metrics\n",
    "    max_probs = np.max(y_pred_proba_ood, axis=1)\n",
    "    mean_confidence = max_probs.mean()\n",
    "    entropy = -np.sum(y_pred_proba_ood * np.log(y_pred_proba_ood + 1e-10), axis=1).mean()\n",
    "    \n",
    "    return {\n",
    "        'OOD Type': ood_name,\n",
    "        'Accuracy': accuracy,\n",
    "        'F1-Score': f1,\n",
    "        'Mean Confidence': mean_confidence,\n",
    "        'Entropy': entropy,\n",
    "        'Performance Drop': in_dist_accuracy - accuracy\n",
    "    }\n",
    "\n",
    "# Evaluate all OOD scenarios\n",
    "ood_results = []\n",
    "ood_results.append(evaluate_ood(X_in_dist_test, y_in_dist_test, scaler, model, 'In-Distribution'))\n",
    "ood_results.append(evaluate_ood(X_ood_shifted, y_ood_shifted, scaler, model, 'Shifted Mean'))\n",
    "ood_results.append(evaluate_ood(X_ood_high_var, y_ood_high_var, scaler, model, 'High Variance'))\n",
    "ood_results.append(evaluate_ood(X_ood_sparse, y_ood_sparse, scaler, model, 'Sparse Features'))\n",
    "ood_results.append(evaluate_ood(X_ood_noisy, y_ood_noisy, scaler, model, 'Noisy'))\n",
    "ood_results.append(evaluate_ood(X_ood_bimodal, y_ood_bimodal, scaler, model, 'Bimodal'))\n",
    "\n",
    "results_df = pd.DataFrame(ood_results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"OUT-OF-DISTRIBUTION EVALUATION RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22da1517",
   "metadata": {},
   "source": [
    "## 4. Visualize OOD Performance\n",
    "\n",
    "Compare model performance across different OOD scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5591acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance comparison visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.suptitle('Out-of-Distribution Robustness Analysis', fontweight='bold', fontsize=16)\n",
    "\n",
    "# Plot 1: Accuracy comparison\n",
    "ax = axes[0, 0]\n",
    "colors = ['green' if x == 'In-Distribution' else 'orange' if x.startswith('Shifted') else 'red' \n",
    "         for x in results_df['OOD Type']]\n",
    "bars1 = ax.bar(range(len(results_df)), results_df['Accuracy'], color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "ax.axhline(y=in_dist_accuracy, color='green', linestyle='--', linewidth=2, label='In-Distribution Baseline')\n",
    "ax.set_xticks(range(len(results_df)))\n",
    "ax.set_xticklabels(results_df['OOD Type'], rotation=45, ha='right')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Accuracy Across OOD Scenarios')\n",
    "ax.set_ylim([0, 1.0])\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 2: F1-Score comparison\n",
    "ax = axes[0, 1]\n",
    "bars2 = ax.bar(range(len(results_df)), results_df['F1-Score'], color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "ax.axhline(y=in_dist_f1, color='green', linestyle='--', linewidth=2, label='In-Distribution Baseline')\n",
    "ax.set_xticks(range(len(results_df)))\n",
    "ax.set_xticklabels(results_df['OOD Type'], rotation=45, ha='right')\n",
    "ax.set_ylabel('F1-Score')\n",
    "ax.set_title('F1-Score Across OOD Scenarios')\n",
    "ax.set_ylim([0, 1.0])\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 3: Performance drop\n",
    "ax = axes[1, 0]\n",
    "perf_drop = results_df['Performance Drop']\n",
    "drop_colors = ['green' if x <= 0 else 'orange' if x < 0.15 else 'red' for x in perf_drop]\n",
    "bars3 = ax.bar(range(len(results_df)), perf_drop, color=drop_colors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "ax.axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
    "ax.set_xticks(range(len(results_df)))\n",
    "ax.set_xticklabels(results_df['OOD Type'], rotation=45, ha='right')\n",
    "ax.set_ylabel('Performance Drop')\n",
    "ax.set_title('Accuracy Loss on OOD Data')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 4: Confidence vs Entropy\n",
    "ax = axes[1, 1]\n",
    "scatter = ax.scatter(results_df['Mean Confidence'], results_df['Entropy'],\n",
    "                    s=300, c=range(len(results_df)), cmap='viridis', alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "for i, ood_type in enumerate(results_df['OOD Type']):\n",
    "    ax.annotate(ood_type, (results_df['Mean Confidence'].iloc[i], results_df['Entropy'].iloc[i]),\n",
    "               fontsize=8, ha='center', va='bottom')\n",
    "ax.set_xlabel('Mean Prediction Confidence')\n",
    "ax.set_ylabel('Prediction Entropy')\n",
    "ax.set_title('Confidence vs. Uncertainty')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/ood_robustness_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c841f00",
   "metadata": {},
   "source": [
    "## 5. Robustness Metrics\n",
    "\n",
    "Compute quantitative robustness measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad82d3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute robustness metrics\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ROBUSTNESS METRICS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 1. Average performance drop\n",
    "ood_only = results_df[results_df['OOD Type'] != 'In-Distribution']\n",
    "avg_drop = ood_only['Performance Drop'].mean()\n",
    "max_drop = ood_only['Performance Drop'].max()\n",
    "\n",
    "print(f\"\\nPerformance Degradation:\")\n",
    "print(f\"  Average drop across OOD scenarios: {avg_drop:.2%}\")\n",
    "print(f\"  Maximum drop: {max_drop:.2%} ({ood_only.loc[ood_only['Performance Drop'].idxmax(), 'OOD Type']})\")\n",
    "\n",
    "# 2. Robustness score (inverse of average drop)\n",
    "robustness_score = 1 - avg_drop\n",
    "print(f\"  Robustness Score: {robustness_score:.2%}\")\n",
    "\n",
    "# 3. Worst-case scenario\n",
    "worst_accuracy = ood_only['Accuracy'].min()\n",
    "worst_scenario = ood_only.loc[ood_only['Accuracy'].idxmin(), 'OOD Type']\n",
    "print(f\"\\nWorst-Case Performance:\")\n",
    "print(f\"  Scenario: {worst_scenario}\")\n",
    "print(f\"  Accuracy: {worst_accuracy:.2%}\")\n",
    "\n",
    "# 4. Confidence calibration on OOD\n",
    "print(f\"\\nConfidence Calibration:\")\n",
    "print(f\"  In-distribution mean confidence: {results_df.loc[0, 'Mean Confidence']:.4f}\")\n",
    "print(f\"  OOD mean confidence: {ood_only['Mean Confidence'].mean():.4f}\")\n",
    "print(f\"  Entropy increase: {ood_only['Entropy'].mean() - results_df.loc[0, 'Entropy']:.4f}\")\n",
    "\n",
    "print(f\"\\nInterpretation:\")\n",
    "if robustness_score > 0.9:\n",
    "    print(\"  ✓ Excellent robustness: Model maintains performance on OOD data\")\n",
    "elif robustness_score > 0.8:\n",
    "    print(\"  ✓ Good robustness: Minor performance degradation on OOD data\")\n",
    "elif robustness_score > 0.7:\n",
    "    print(\"  ⚠ Moderate robustness: Noticeable performance degradation on OOD data\")\n",
    "else:\n",
    "    print(\"  ✗ Poor robustness: Significant performance degradation on OOD data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee7836e",
   "metadata": {},
   "source": [
    "## 6. Per-Scenario Analysis\n",
    "\n",
    "Deep dive into each OOD scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a159ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PER-SCENARIO ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "scenarios = [\n",
    "    (\"Shifted Mean\", \"Audio with different energy/loudness profiles (e.g., live vs. studio recordings)\"),\n",
    "    (\"High Variance\", \"Extreme dynamics (e.g., dynamic classical music)\"),\n",
    "    (\"Sparse Features\", \"Lossy compression artifacts (e.g., MP3-compressed audio)\"),\n",
    "    (\"Noisy\", \"Degraded audio quality (e.g., low-bitrate streaming)\"),\n",
    "    (\"Bimodal\", \"Hybrid genres / cover songs (e.g., acoustic pop cover)\")\n",
    "]\n",
    "\n",
    "for scenario_name, description in scenarios:\n",
    "    scenario_row = results_df[results_df['OOD Type'] == scenario_name]\n",
    "    if len(scenario_row) > 0:\n",
    "        acc = scenario_row['Accuracy'].values[0]\n",
    "        drop = scenario_row['Performance Drop'].values[0]\n",
    "        conf = scenario_row['Mean Confidence'].values[0]\n",
    "        \n",
    "        print(f\"\\n{scenario_name}:\")\n",
    "        print(f\"  Description: {description}\")\n",
    "        print(f\"  Accuracy: {acc:.2%} (drop: {drop:.2%})\")\n",
    "        print(f\"  Mean Confidence: {conf:.4f}\")\n",
    "        \n",
    "        if drop < 0.1:\n",
    "            print(f\"  Assessment: Model robust to this scenario ✓\")\n",
    "        elif drop < 0.2:\n",
    "            print(f\"  Assessment: Minor performance degradation ⚠\")\n",
    "        else:\n",
    "            print(f\"  Assessment: Significant performance degradation ✗\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9620f63",
   "metadata": {},
   "source": [
    "## 7. Summary and Recommendations\n",
    "\n",
    "Synthesize OOD evaluation findings and provide recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0856b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"OUT-OF-DISTRIBUTION EVALUATION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nKey Findings:\")\n",
    "print(f\"  1. In-distribution accuracy: {in_dist_accuracy:.2%}\")\n",
    "print(f\"  2. Average OOD accuracy: {ood_only['Accuracy'].mean():.2%}\")\n",
    "print(f\"  3. Overall robustness score: {robustness_score:.2%}\")\n",
    "\n",
    "print(f\"\\nMost Robust To:\")\n",
    "most_robust = ood_only.loc[ood_only['Performance Drop'].idxmin()]\n",
    "print(f\"  • {most_robust['OOD Type']}: {most_robust['Accuracy']:.2%}\")\n",
    "\n",
    "print(f\"\\nLeast Robust To:\")\n",
    "least_robust = ood_only.loc[ood_only['Performance Drop'].idxmax()]\n",
    "print(f\"  • {least_robust['OOD Type']}: {least_robust['Accuracy']:.2%}\")\n",
    "\n",
    "print(f\"\\nRecommendations for Production Deployment:\")\n",
    "if robustness_score < 0.8:\n",
    "    print(f\"  1. Implement model ensemble for improved robustness\")\n",
    "    print(f\"  2. Apply data augmentation to training set (synthetic OOD data)\")\n",
    "    print(f\"  3. Consider domain adaptation techniques\")\n",
    "    print(f\"  4. Implement input validation and preprocessing normalization\")\n",
    "    print(f\"  5. Add confidence-based filtering for low-confidence predictions\")\n",
    "else:\n",
    "    print(f\"  1. Model shows acceptable robustness for deployment\")\n",
    "    print(f\"  2. Monitor performance on production data for drift\")\n",
    "    print(f\"  3. Implement periodic retraining with new data\")\n",
    "    print(f\"  4. Use confidence scores for reliability estimates\")\n",
    "\n",
    "print(f\"\\n✓ Out-of-distribution evaluation complete!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
